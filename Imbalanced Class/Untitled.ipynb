{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  balance  var1  var2  var3  var4\n",
       "0       B     1     1     1     1\n",
       "1       R     1     1     1     2\n",
       "2       R     1     1     1     3\n",
       "3       R     1     1     1     4\n",
       "4       R     1     1     1     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('balance-scale.data', \n",
    "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    " \n",
    "# Display example observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L    288\n",
       "R    288\n",
       "B     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're going to label each observation as 1 (positive class) if the scale is balanced or 0 (negative class) if the scale is not balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1     49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    " \n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Danger of Imbalanced Classes\n",
    "### Now that we have a dataset, we can really show the dangers of imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_0 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_0 = clf_0.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#How's the accuracy?\n",
    "print( accuracy_score(pred_y_0, y) )\n",
    "# 0.9216\n",
    "# Should we be excited?\n",
    "print( np.unique( pred_y_0 ) )\n",
    "# [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, this model is only predicting 0, which means it's completely ignoring the minority class in favor of the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-sample Minority Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we'll create a new DataFrame with an up-sampled minority class. Here are the steps:\n",
    "\n",
    "### First, we'll separate observations from each class into different DataFrames.\n",
    "### Next, we'll resample the minority class with replacement, setting the number of samples to match that of the majority class.\n",
    "### Finally, we'll combine the up-sampled minority class DataFrame with the original majority class DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    576\n",
       "0    576\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=576,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.balance.value_counts()\n",
    "# 1    576\n",
    "# 0    576\n",
    "# Name: balance, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5138888888888888\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_1 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_1 = clf_1.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_1 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_1) )\n",
    "# 0.513888888889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down-sample Majority Class\n",
    "Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "\n",
    "The most common heuristic for doing so is resampling without replacement.\n",
    "\n",
    "The process is similar to that of up-sampling. Here are the steps:\n",
    "\n",
    "First, we'll separate observations from each class into different DataFrames.\n",
    "Next, we'll resample the majority class without replacement, setting the number of samples to match that of the minority class.\n",
    "Finally, we'll combine the down-sampled majority class DataFrame with the original minority class DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    49\n",
       "0    49\n",
       "Name: balance, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.balance.value_counts()\n",
    "# 1    49\n",
    "# 0    49\n",
    "# Name: balance, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.5816326530612245\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = clf_2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_2 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_2) )\n",
    "# 0.581632653061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4541919722647967,\n",
       " 0.4820596221328393,\n",
       " 0.4686232706639249,\n",
       " 0.4786837883268909,\n",
       " 0.5814385682015961]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Predict class probabilities\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    " \n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    " \n",
    "prob_y_2[:5] # Example\n",
    "# [0.45419197226479618,\n",
    "#  0.48205962213283882,\n",
    "#  0.46862327066392456,\n",
    "#  0.47868378832689096,\n",
    "#  0.58143856820159667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5680966264056644\n"
     ]
    }
   ],
   "source": [
    "print( roc_auc_score(y, prob_y_2) )\n",
    "# 0.568096626406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset Model AUROC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4773011245314452\n"
     ]
    }
   ],
   "source": [
    "prob_y_0 = clf_0.predict_proba(X)\n",
    "prob_y_0 = [p[1] for p in prob_y_0]\n",
    " \n",
    "print( roc_auc_score(y, prob_y_0) )\n",
    "# 0.530718537415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Penalize Algorithms (Cost-Sensitive Training)\n",
    "The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class.\n",
    "\n",
    " A popular algorithm for this technique is Penalized-SVM:\n",
    "\n",
    "During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    " We also want to include the argument probability=True  if we want to enable probability estimates for SVM algorithms.\n",
    "\n",
    "### Let's train a model using Penalized-SVM on the original imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.688\n",
      "0.46947633219954643\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    " \n",
    "clf_3.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_3 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_3) )\n",
    "# 0.688\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y_3 = clf_3.predict_proba(X)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "print( roc_auc_score(y, prob_y_3) )\n",
    "# 0.5305236678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE BASED\n",
    "The final tactic we'll consider is using tree-based algorithms. Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes.\n",
    "\n",
    "In modern applied machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we'll jump right into those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.9808\n",
      "0.9996456916099774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "clf_4 = RandomForestClassifier()\n",
    "clf_4.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = clf_4.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred_y_4 ) )\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_4) )\n",
    "# 0.9744\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y_4 = clf_4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y, prob_y_4) )\n",
    "# 0.999078798186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
